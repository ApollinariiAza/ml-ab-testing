import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import norm, chi2_contingency, ttest_ind
import warnings
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

warnings.filterwarnings('ignore')

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑÑ‚Ğ¸Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class TestType(Enum):
    """Ğ¢Ğ¸Ğ¿Ñ‹ A/B Ñ‚ĞµÑÑ‚Ğ¾Ğ²"""
    CONVERSION = "conversion"  # ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ (Ğ±Ğ¸Ğ½Ğ¾Ğ¼Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°)
    CONTINUOUS = "continuous"  # ĞĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° (ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ)
    COUNT = "count"           # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°

@dataclass
class TestResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ A/B Ñ‚ĞµÑÑ‚Ğ°"""
    test_type: TestType
    group_a_size: int
    group_b_size: int
    group_a_metric: float
    group_b_metric: float
    p_value: float
    confidence_interval: Tuple[float, float]
    effect_size: float
    power: float
    is_significant: bool
    conclusion: str

class ABTesting:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ A/B Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
    
    def __init__(self, alpha: float = 0.05):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ A/B Ñ‚ĞµÑÑ‚Ğ°
        
        Args:
            alpha: Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 0.05)
        """
        self.alpha = alpha
        self.confidence_level = 1 - alpha
        
    def generate_sample_data(self, 
                           n_control: int = 1000, 
                           n_treatment: int = 1000,
                           test_type: TestType = TestType.CONVERSION,
                           effect_size: float = 0.1) -> pd.DataFrame:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ A/B Ñ‚ĞµÑÑ‚Ğ°
        
        Args:
            n_control: Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹
            n_treatment: Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹  
            test_type: Ğ¢Ğ¸Ğ¿ Ñ‚ĞµÑÑ‚Ğ°
            effect_size: Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ„Ñ„ĞµĞºÑ‚Ğ°
            
        Returns:
            DataFrame Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
        """
        np.random.seed(42)
        
        if test_type == TestType.CONVERSION:
            # Ğ‘Ğ¸Ğ½Ğ¾Ğ¼Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ)
            p_control = 0.10  # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ 10%
            p_treatment = p_control + effect_size
            
            control_conversions = np.random.binomial(1, p_control, n_control)
            treatment_conversions = np.random.binomial(1, p_treatment, n_treatment)
            
            data = pd.DataFrame({
                'user_id': range(n_control + n_treatment),
                'group': ['A'] * n_control + ['B'] * n_treatment,
                'converted': np.concatenate([control_conversions, treatment_conversions])
            })
            
        elif test_type == TestType.CONTINUOUS:
            # ĞĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ°)
            mean_control = 100.0
            mean_treatment = mean_control + effect_size * 10  # Ğ­Ñ„Ñ„ĞµĞºÑ‚ Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ…
            std = 25.0
            
            control_values = np.random.normal(mean_control, std, n_control)
            treatment_values = np.random.normal(mean_treatment, std, n_treatment)
            
            data = pd.DataFrame({
                'user_id': range(n_control + n_treatment),
                'group': ['A'] * n_control + ['B'] * n_treatment,
                'revenue': np.concatenate([control_values, treatment_values])
            })
            
        elif test_type == TestType.COUNT:
            # Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚Ğ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°ĞºĞ°Ğ·Ğ¾Ğ²)
            lambda_control = 2.0
            lambda_treatment = lambda_control + effect_size
            
            control_counts = np.random.poisson(lambda_control, n_control)
            treatment_counts = np.random.poisson(lambda_treatment, n_treatment)
            
            data = pd.DataFrame({
                'user_id': range(n_control + n_treatment),
                'group': ['A'] * n_control + ['B'] * n_treatment,
                'orders_count': np.concatenate([control_counts, treatment_counts])
            })
        
        return data
    
    def conversion_test(self, data: pd.DataFrame, 
                       conversion_col: str = 'converted') -> TestResult:
        """
        ĞŸÑ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚ĞµÑÑ‚ Ğ½Ğ° ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ (Ğ±Ğ¸Ğ½Ğ¾Ğ¼Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°)
        
        Args:
            data: DataFrame Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
            conversion_col: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸ÑĞ¼Ğ¸
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ°
        """
        group_a = data[data['group'] == 'A'][conversion_col]
        group_b = data[data['group'] == 'B'][conversion_col]
        
        # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        n_a, n_b = len(group_a), len(group_b)
        conversions_a = group_a.sum()
        conversions_b = group_b.sum()
        rate_a = conversions_a / n_a
        rate_b = conversions_b / n_b
        
        # Z-Ñ‚ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¹
        pooled_rate = (conversions_a + conversions_b) / (n_a + n_b)
        pooled_se = np.sqrt(pooled_rate * (1 - pooled_rate) * (1/n_a + 1/n_b))
        z_score = (rate_b - rate_a) / pooled_se
        p_value = 2 * (1 - norm.cdf(abs(z_score)))
        
        # Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¹
        se_diff = np.sqrt(rate_a * (1 - rate_a) / n_a + rate_b * (1 - rate_b) / n_b)
        z_critical = norm.ppf(1 - self.alpha / 2)
        diff = rate_b - rate_a
        ci_lower = diff - z_critical * se_diff
        ci_upper = diff + z_critical * se_diff
        
        # Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ„Ñ„ĞµĞºÑ‚Ğ° (Cohen's h)
        effect_size = 2 * (np.arcsin(np.sqrt(rate_b)) - np.arcsin(np.sqrt(rate_a)))
        
        # ĞœĞ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ° (Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ¶Ñ‘Ğ½Ğ½Ğ¾)
        power = self._calculate_power_proportion(rate_a, rate_b, n_a, n_b)
        
        is_significant = p_value < self.alpha
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´
        if is_significant:
            direction = "Ğ²Ñ‹ÑˆĞµ" if rate_b > rate_a else "Ğ½Ğ¸Ğ¶Ğµ"
            conclusion = f"ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ B ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ {direction} Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ A"
        else:
            conclusion = "ĞĞµÑ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸"
        
        return TestResult(
            test_type=TestType.CONVERSION,
            group_a_size=n_a,
            group_b_size=n_b,
            group_a_metric=rate_a,
            group_b_metric=rate_b,
            p_value=p_value,
            confidence_interval=(ci_lower, ci_upper),
            effect_size=effect_size,
            power=power,
            is_significant=is_significant,
            conclusion=conclusion
        )
    
    def continuous_test(self, data: pd.DataFrame, 
                       metric_col: str = 'revenue') -> TestResult:
        """
        ĞŸÑ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚ĞµÑÑ‚ Ğ´Ğ»Ñ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ (t-Ñ‚ĞµÑÑ‚)
        
        Args:
            data: DataFrame Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
            metric_col: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¾Ğ¹
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ°
        """
        group_a = data[data['group'] == 'A'][metric_col]
        group_b = data[data['group'] == 'B'][metric_col]
        
        # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        n_a, n_b = len(group_a), len(group_b)
        mean_a, mean_b = group_a.mean(), group_b.mean()
        std_a, std_b = group_a.std(ddof=1), group_b.std(ddof=1)
        
        # t-Ñ‚ĞµÑÑ‚ Ğ£ÑĞ»Ñ‡Ğ° (Ğ½Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ñ€Ğ°Ğ²ĞµĞ½ÑÑ‚Ğ²Ğ¾ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¹)
        t_stat, p_value = ttest_ind(group_b, group_a, equal_var=False)
        
        # Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚Ğ¸ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ…
        se_diff = np.sqrt(std_a**2 / n_a + std_b**2 / n_b)
        df = (std_a**2 / n_a + std_b**2 / n_b)**2 / (
            (std_a**2 / n_a)**2 / (n_a - 1) + (std_b**2 / n_b)**2 / (n_b - 1)
        )
        t_critical = stats.t.ppf(1 - self.alpha / 2, df)
        diff = mean_b - mean_a
        ci_lower = diff - t_critical * se_diff
        ci_upper = diff + t_critical * se_diff
        
        # Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ„Ñ„ĞµĞºÑ‚Ğ° (Cohen's d)
        pooled_std = np.sqrt(((n_a - 1) * std_a**2 + (n_b - 1) * std_b**2) / (n_a + n_b - 2))
        effect_size = diff / pooled_std
        
        # ĞœĞ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ°
        power = self._calculate_power_ttest(mean_a, mean_b, std_a, std_b, n_a, n_b)
        
        is_significant = p_value < self.alpha
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´
        if is_significant:
            direction = "Ğ²Ñ‹ÑˆĞµ" if mean_b > mean_a else "Ğ½Ğ¸Ğ¶Ğµ"
            conclusion = f"Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ B ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ {direction} Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ A"
        else:
            conclusion = "ĞĞµÑ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸"
        
        return TestResult(
            test_type=TestType.CONTINUOUS,
            group_a_size=n_a,
            group_b_size=n_b,
            group_a_metric=mean_a,
            group_b_metric=mean_b,
            p_value=p_value,
            confidence_interval=(ci_lower, ci_upper),
            effect_size=effect_size,
            power=power,
            is_significant=is_significant,
            conclusion=conclusion
        )
    
    def _calculate_power_proportion(self, p1: float, p2: float, 
                                  n1: int, n2: int) -> float:
        """Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¹"""
        pooled_p = (p1 * n1 + p2 * n2) / (n1 + n2)
        se_null = np.sqrt(pooled_p * (1 - pooled_p) * (1/n1 + 1/n2))
        se_alt = np.sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)
        
        z_alpha = norm.ppf(1 - self.alpha / 2)
        z_beta = (abs(p2 - p1) - z_alpha * se_null) / se_alt
        power = norm.cdf(z_beta)
        return max(0, min(1, power))
    
    def _calculate_power_ttest(self, m1: float, m2: float, s1: float, s2: float,
                              n1: int, n2: int) -> float:
        """Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ t-Ñ‚ĞµÑÑ‚Ğ°"""
        pooled_std = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))
        effect_size = abs(m2 - m1) / pooled_std
        se = pooled_std * np.sqrt(1/n1 + 1/n2)
        
        df = n1 + n2 - 2
        t_alpha = stats.t.ppf(1 - self.alpha / 2, df)
        t_beta = (abs(m2 - m1) - t_alpha * se) / se
        power = 1 - stats.t.cdf(t_beta, df)
        return max(0, min(1, power))
    
    def plot_results(self, data: pd.DataFrame, result: TestResult, 
                    metric_col: str = None, save_path: str = None):
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² A/B Ñ‚ĞµÑÑ‚Ğ°
        
        Args:
            data: DataFrame Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
            result: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ°
            metric_col: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¾Ğ¹
            save_path: ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ A/B Ñ‚ĞµÑÑ‚Ğ°', fontsize=16, fontweight='bold')
        
        if result.test_type == TestType.CONVERSION:
            self._plot_conversion_results(data, result, axes)
        else:
            self._plot_continuous_results(data, result, metric_col, axes)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ
        self._add_info_panel(fig, result)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_conversion_results(self, data: pd.DataFrame, result: TestResult, axes):
        """Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ² ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¸"""
        # 1. Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¹
        conversion_data = data.groupby('group')['converted'].agg(['count', 'sum']).reset_index()
        conversion_data['rate'] = conversion_data['sum'] / conversion_data['count']
        
        ax1 = axes[0, 0]
        bars = ax1.bar(conversion_data['group'], conversion_data['rate'], 
                      color=['skyblue', 'lightcoral'])
        ax1.set_title('ĞšĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¿Ğ¾ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼')
        ax1.set_ylabel('Conversion Rate')
        ax1.set_ylim(0, max(conversion_data['rate']) * 1.2)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹
        for bar, rate in zip(bars, conversion_data['rate']):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{rate:.3f}', ha='center', va='bottom')
        
        # 2. Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»
        ax2 = axes[0, 1]
        ci_lower, ci_upper = result.confidence_interval
        diff = result.group_b_metric - result.group_a_metric
        
        ax2.errorbar([0], [diff], yerr=[[diff - ci_lower], [ci_upper - diff]], 
                    fmt='o', capsize=5, capthick=2, color='red', markersize=8)
        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax2.set_title('Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚Ğ¸')
        ax2.set_ylabel('Ğ Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¹')
        ax2.set_xlim(-0.5, 0.5)
        ax2.set_xticks([])
        
        # 3. Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğº
        ax3 = axes[1, 0]
        sample_sizes = [result.group_a_size, result.group_b_size]
        ax3.bar(['Group A', 'Group B'], sample_sizes, color=['skyblue', 'lightcoral'])
        ax3.set_title('Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğº')
        ax3.set_ylabel('ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹')
        
        # 4. Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        ax4 = axes[1, 1]
        metrics = ['p-value', 'Effect Size', 'Power']
        values = [result.p_value, abs(result.effect_size), result.power]
        
        colors = ['red' if result.p_value < 0.05 else 'gray', 'blue', 'green']
        bars = ax4.bar(metrics, values, color=colors, alpha=0.7)
        ax4.set_title('Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸')
        ax4.set_ylabel('Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ')
        
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.3f}', ha='center', va='bottom')
    
    def _plot_continuous_results(self, data: pd.DataFrame, result: TestResult, 
                                metric_col: str, axes):
        """Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ½ĞµĞ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº"""
        group_a_data = data[data['group'] == 'A'][metric_col]
        group_b_data = data[data['group'] == 'B'][metric_col]
        
        # 1. Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ
        ax1 = axes[0, 0]
        ax1.hist(group_a_data, alpha=0.7, bins=30, label='Group A', color='skyblue')
        ax1.hist(group_b_data, alpha=0.7, bins=30, label='Group B', color='lightcoral')
        ax1.set_title('Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸')
        ax1.set_xlabel(metric_col)
        ax1.set_ylabel('Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ°')
        ax1.legend()
        
        # 2. Box plots
        ax2 = axes[0, 1]
        data.boxplot(column=metric_col, by='group', ax=ax2)
        ax2.set_title('Box plots Ğ¿Ğ¾ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼')
        ax2.set_xlabel('Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°')
        ax2.set_ylabel(metric_col)
        
        # 3. Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»
        ax3 = axes[1, 0]
        ci_lower, ci_upper = result.confidence_interval
        diff = result.group_b_metric - result.group_a_metric
        
        ax3.errorbar([0], [diff], yerr=[[diff - ci_lower], [ci_upper - diff]], 
                    fmt='o', capsize=5, capthick=2, color='red', markersize=8)
        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax3.set_title('Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚Ğ¸')
        ax3.set_ylabel(f'Ğ Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… ({metric_col})')
        ax3.set_xlim(-0.5, 0.5)
        ax3.set_xticks([])
        
        # 4. Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        ax4 = axes[1, 1]
        metrics = ['p-value', 'Effect Size', 'Power']
        values = [result.p_value, abs(result.effect_size), result.power]
        
        colors = ['red' if result.p_value < 0.05 else 'gray', 'blue', 'green']
        bars = ax4.bar(metrics, values, color=colors, alpha=0.7)
        ax4.set_title('Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸')
        ax4.set_ylabel('Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ')
        
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.3f}', ha='center', va='bottom')
    
    def _add_info_panel(self, fig, result: TestResult):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸"""
        info_text = f"""
        ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« A/B Ğ¢Ğ•Ğ¡Ğ¢Ğ
        
        Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğº: A = {result.group_a_size}, B = {result.group_b_size}
        ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° A: {result.group_a_metric:.4f}
        ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° B: {result.group_b_metric:.4f}
        
        p-value: {result.p_value:.4f}
        Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ„Ñ„ĞµĞºÑ‚Ğ°: {result.effect_size:.4f}
        ĞœĞ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ°: {result.power:.4f}
        
        Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»: [{result.confidence_interval[0]:.4f}, {result.confidence_interval[1]:.4f}]
        
        ğŸ¯ Ğ’Ğ«Ğ’ĞĞ”: {result.conclusion}
        """
        
        fig.text(0.02, 0.02, info_text, fontsize=10, 
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8),
                verticalalignment='bottom')
    
    def sample_size_calculator(self, baseline_rate: float, 
                             expected_lift: float, 
                             power: float = 0.8,
                             alpha: float = 0.05) -> int:
        """
        Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ´Ğ»Ñ A/B Ñ‚ĞµÑÑ‚Ğ°
        
        Args:
            baseline_rate: Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ
            expected_lift: ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ (Ğ² Ğ´Ğ¾Ğ»ÑÑ…, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ 0.1 Ğ´Ğ»Ñ 10%)
            power: Ğ–ĞµĞ»Ğ°ĞµĞ¼Ğ°Ñ Ğ¼Ğ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ°
            alpha: Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
            
        Returns:
            ĞĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹
        """
        treatment_rate = baseline_rate * (1 + expected_lift)
        
        z_alpha = norm.ppf(1 - alpha / 2)
        z_beta = norm.ppf(power)
        
        p_avg = (baseline_rate + treatment_rate) / 2
        
        n = (2 * p_avg * (1 - p_avg) * (z_alpha + z_beta)**2) / (baseline_rate - treatment_rate)**2
        
        return int(np.ceil(n))
    
    def generate_report(self, result: TestResult) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ¿Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼ A/B Ñ‚ĞµÑÑ‚Ğ°
        
        Args:
            result: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ°
            
        Returns:
            Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
        """
        report = f"""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                        A/B TEST REPORT                        â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ Ğ¢Ğ¸Ğ¿ Ñ‚ĞµÑÑ‚Ğ°: {result.test_type.value.upper()}
        â•‘ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {self.alpha}
        â•‘ Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ: {self.confidence_level:.1%}
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ Ğ ĞĞ—ĞœĞ•Ğ Ğ« Ğ’Ğ«Ğ‘ĞĞ ĞĞš:
        â•‘   â€¢ Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° A (ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ): {result.group_a_size:,}
        â•‘   â€¢ Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° B (Ñ‚ĞµÑÑ‚):     {result.group_b_size:,}
        â•‘   â€¢ ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€:        {result.group_a_size + result.group_b_size:,}
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ ĞĞ¡ĞĞĞ’ĞĞ«Ğ• ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜:
        â•‘   â€¢ Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° A: {result.group_a_metric:.4f}
        â•‘   â€¢ Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° B: {result.group_b_metric:.4f}
        â•‘   â€¢ Ğ Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ: {result.group_b_metric - result.group_a_metric:.4f}
        â•‘   â€¢ ĞÑ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ: {((result.group_b_metric / result.group_a_metric - 1) * 100):+.2f}%
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«:
        â•‘   â€¢ p-value:           {result.p_value:.6f}
        â•‘   â€¢ Ğ Ğ°Ğ·Ğ¼ĞµÑ€ ÑÑ„Ñ„ĞµĞºÑ‚Ğ°:    {result.effect_size:.4f}
        â•‘   â€¢ ĞœĞ¾Ñ‰Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ°:    {result.power:.4f}
        â•‘   â€¢ Ğ”Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»: [{result.confidence_interval[0]:+.4f}, {result.confidence_interval[1]:+.4f}]
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ—ĞĞĞ§Ğ˜ĞœĞĞ¡Ğ¢Ğ¬: {"âœ“ Ğ”Ğ" if result.is_significant else "âœ— ĞĞ•Ğ¢"}
        â•‘
        â•‘ Ğ’Ğ«Ğ’ĞĞ”:
        â•‘ {result.conclusion}
        â•‘
        """
        
        if result.is_significant:
            report += "â•‘ ğŸ¯ Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ¯: Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ¼ĞµĞµÑ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ñ‹Ğ¹\n"
            report += "â•‘    ÑÑ„Ñ„ĞµĞºÑ‚. Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹.\n"
        else:
            report += "â•‘ âš ï¸  Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ¯: ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ.\n"
            report += "â•‘    ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚Ğµ Ñ‚ĞµÑÑ‚ Ğ¸Ğ»Ğ¸ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ÑŒÑ‚Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸.\n"
        
        report += "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        return report